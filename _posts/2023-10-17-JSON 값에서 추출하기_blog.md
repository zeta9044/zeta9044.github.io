---
layout: post
title: "JSON 값에서 추출하기"
date: 2023-10-17
tags: [추출, JSON, 값]
categories: blog
---

## 사용자 입력:
>   select a.cluster_nm, a.app_type, a.srv_ip, a.context_name
       , 'src.kafka.bootstrap.servers' as json_key
       , trim(split_part(unnest(string_to_array(replace((a.context_value::json->'src.kafka.bootstrap.servers')::varchar,'"',''), ',')),':',1)) as json_value
    from zq_kafka_info a 이런 postgresql 쿼리가 있는데, json_value 추출하는 부분을 자세히 설명해줘.   
       , trim(split_part(unnest(string_to_array(replace((a.context_value::json->'src.kafka.bootstrap.servers')::varchar,'"',''), ',')),':',1)) as json_value

## ChatGPT 응답:
> 물론이죠! 해당 쿼리에서 JSON 값에서 특정 부분을 추출하는 로직을 세분화해서 설명해 드리겠습니다.

먼저 전체적인 절차부터 간략하게 설명하자면:
1. `a.context_value::json->'src.kafka.bootstrap.servers'`를 사용하여 `context_value` JSON 컬럼에서 'src.kafka.bootstrap.servers' 키의 값을 추출합니다.
2. 이 값을 문자열로 변환하고, 문자열에서 큰따옴표(")를 제거합니다.
3. 제거된 문자열을 `,` 기준으로 나누어 배열로 만듭니다.
4. 이 배열의 각 요소를 순회하면서 `:`를 기준으로 나눈 후 첫 번째 부분을 선택합니다.
5. 마지막으로 선택된 문자열의 양쪽 끝에서 공백을 제거합니다.

자세한 설명은 아래와 같습니다:

1. **JSON Value 추출**:
   ```sql
   a.context_value::json->'src.kafka.bootstrap.servers'
   ```
   여기서는 `a.context_value` 필드의 JSON 데이터에서 `'src.kafka.bootstrap.servers'` 키에 해당하는 값을 추출합니다.

2. **문자열 변환 및 큰따옴표 제거**:
   ```sql
   replace((...)::varchar,'"','')
   ```
   JSON 값은 문자열로 변환되고 (`::varchar`), 그 다음에 `replace` 함수를 사용하여 큰따옴표(")를 제거합니다.

3. **`,` 기준으로 문자열 분리**:
   ```sql
   string_to_array(..., ',')
   ```
   `string_to_array` 함수는 주어진 문자열을 첫 번째 매개변수의 `,`를 기준으로 분리하여 배열로 반환합니다.

4. **배열 값 언네스트 및 `:` 기준 분리**:
   ```sql
   split_part(unnest(...), ':', 1)
   ```
   `unnest` 함수는 배열의 각 항목을 여러 행으로 분리합니다. 그 후, `split_part` 함수는 `:`를 기준으로 문자열을 분리하고, 첫 번째 부분 (index 1)을 선택합니다.

5. **공백 제거**:
   ```sql
   trim(...)
   ```
   `trim` 함수는 문자열의 앞뒤 공백을 제거합니다.

결과적으로, 이 로직은 'src.kafka.bootstrap.servers' 키의 값에서 서버 IP 주소나 도메인 이름만을 추출하는 것 같습니다. (예: "192.168.1.1:9092,192.168.1.2:9092" => "192.168.1.1" 및 "192.168.1.2")

## 사용자 입력:
> 그러면, 위 쿼리를 oracle로 바꿔줘.

## ChatGPT 응답:
> PostgreSQL에서 사용된 몇몇 함수들은 Oracle에서 그대로 사용할 수 없으므로, Oracle의 기능에 맞게 쿼리를 수정해야 합니다.

다음은 위의 PostgreSQL 쿼리를 Oracle 쿼리로 변환한 예입니다:

```sql
SELECT a.cluster_nm, 
       a.app_type, 
       a.srv_ip, 
       a.context_name, 
       'src.kafka.bootstrap.servers' as json_key,
       TRIM(SUBSTR(REGEXP_SUBSTR(REGEXP_REPLACE(a.context_value, '"', ''), '[^,]+', 1, COLUMN_VALUE), 1, INSTR(REGEXP_SUBSTR(REGEXP_REPLACE(a.context_value, '"', ''), '[^,]+', 1, COLUMN_VALUE), ':')-1)) as json_value
FROM zq_kafka_info a,
     TABLE(CAST(MULTISET(SELECT LEVEL 
                         FROM DUAL 
                         CONNECT BY LEVEL <= LENGTH(REGEXP_REPLACE(a.context_value, '"', ''))-LENGTH(REPLACE(REGEXP_REPLACE(a.context_value, '"', ''), ',', ''))+1) 
                AS SYS.ODCINUMBERLIST))
WHERE INSTR(REGEXP_REPLACE(a.context_value, '"', ''), ',', 1, LEVEL) != 0 
   OR LEVEL = 1
```

설명:
1. Oracle에서는 `string_to_array`와 같은 기능을 갖는 내장 함수가 없기 때문에, 문자열의 개수를 세고 해당 수만큼 `CONNECT BY LEVEL`을 사용하여 숫자를 생성합니다.
2. `MULTISET`와 `TABLE`을 사용하여 이 숫자들을 테이블로 변환하고, 그것을 통해 문자열을 `,` 기준으로 나눕니다.
3. `REGEXP_SUBSTR`을 사용하여 문자열을 `,` 기준으로 분리한 후, `INSTR`와 `SUBSTR`을 사용하여 `:` 기준으로 문자열을 다시 분리합니다.
4. 결과적으로 원하는 서버 IP나 도메인 이름을 얻을 수 있습니다.

**주의**: 이 쿼리는 기본적인 Oracle 환경에서 실행 가능하도록 작성되었으나, 실제 데이터와 환경에 따라 추가적인 조정이 필요할 수 있습니다.

## 사용자 입력:
> SQL Error [1788] [42000]: ORA-01788: CONNECT BY 구를 지정해 주십시오



Error position: line: 7 pos: 362 이런 오류가 발생하네.

## ChatGPT 응답:
> 죄송합니다. `CONNECT BY` 절에서 조건을 빠뜨렸네요.

`CONNECT BY` 절은 계층적 쿼리에서 사용하는데, 특정 조건에 따라 계층을 정의합니다. Oracle에서는 `,`로 분리된 문자열을 분리하기 위해 `CONNECT BY LEVEL`을 사용하며, 적절한 조건을 제공하여 숫자를 생성합니다.

쿼리를 수정하겠습니다:

```sql
SELECT a.cluster_nm, 
       a.app_type, 
       a.srv_ip, 
       a.context_name, 
       'src.kafka.bootstrap.servers' as json_key,
       TRIM(SUBSTR(REGEXP_SUBSTR(REGEXP_REPLACE(a.context_value, '"', ''), '[^,]+', 1, COLUMN_VALUE), 1, INSTR(REGEXP_SUBSTR(REGEXP_REPLACE(a.context_value, '"', ''), '[^,]+', 1, COLUMN_VALUE), ':')-1)) as json_value
FROM zq_kafka_info a,
     TABLE(CAST(MULTISET(SELECT LEVEL 
                         FROM DUAL 
                         CONNECT BY PRIOR LEVEL <= LENGTH(REGEXP_REPLACE(a.context_value, '"', ''))-LENGTH(REPLACE(REGEXP_REPLACE(a.context_value, '"', ''), ',', ''))+1 
                                    AND PRIOR DBMS_RANDOM.VALUE IS NOT NULL) 
                AS SYS.ODCINUMBERLIST))
WHERE INSTR(REGEXP_REPLACE(a.context_value, '"', ''), ',', 1, LEVEL) != 0 
   OR LEVEL = 1
```

변경 사항:
1. `CONNECT BY` 절에 `PRIOR LEVEL`과 `PRIOR DBMS_RANDOM.VALUE IS NOT NULL`을 추가하여 순환을 방지하였습니다. 
2. `PRIOR` 키워드는 이전 행의 값을 참조합니다.
3. `DBMS_RANDOM.VALUE`는 순환을 방지하기 위해 추가한 임의의 함수입니다. 

다시 시도해 보시고 문제가 계속 발생할 경우 알려주십시오.

## 사용자 입력:
> SQL Error [976] [42000]: ORA-00976: 여기에는 지정된 의사 열 또는 연산자가 허용되지 않습니다.
 이런 오류가 발생하네.

## ChatGPT 응답:
> 죄송합니다. 이 오류는 `LEVEL`을 해당 방식으로 사용하는 것이 허용되지 않기 때문에 발생합니다.

Oracle에서 문자열을 `,`로 나누려면 다소 복잡한 방식을 사용해야 합니다. 다음은 수정된 쿼리입니다:

```sql
WITH CTE AS (
    SELECT a.cluster_nm, 
           a.app_type, 
           a.srv_ip, 
           a.context_name, 
           'src.kafka.bootstrap.servers' as json_key,
           REGEXP_REPLACE(a.context_value, '"', '') AS cleaned_value,
           LEVEL AS lvl
    FROM zq_kafka_info a
    CONNECT BY PRIOR a.cluster_nm = a.cluster_nm
        AND PRIOR DBMS_RANDOM.VALUE IS NOT NULL
        AND LEVEL <= LENGTH(REGEXP_REPLACE(a.context_value, '"', '')) - LENGTH(REPLACE(REGEXP_REPLACE(a.context_value, '"', ''), ',', '')) + 1
)
SELECT cluster_nm, app_type, srv_ip, context_name, json_key,
       TRIM(SUBSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), 1, INSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), ':')-1)) as json_value
FROM CTE
WHERE INSTR(cleaned_value, ',', 1, lvl) != 0 OR lvl = 1
```

이 쿼리에서는:

1. `WITH CTE AS`를 사용하여 Common Table Expression (CTE)를 정의하였습니다. CTE는 하나의 SQL 문 안에서 여러 번 참조할 수 있는 일시적인 결과 집합을 생성합니다.
2. CTE 내에서 `CONNECT BY` 절은 재귀적으로 `LEVEL`을 증가시키며 문자열 내의 `,`의 개수를 계산하고 이를 기반으로 행을 생성합니다.
3. 메인 쿼리에서는 CTE의 결과를 사용하여 각 `,`로 나누어진 값을 처리합니다.

이 쿼리를 실행해 보세요. 만약 추가적인 문제가 발생하면 알려주세요.

## 사용자 입력:
> 음, 거의 다 됐는데, 원래 postgresql이 다음과 같아.   select a.cluster_nm, a.app_type, a.srv_ip, a.context_name
       , 'src.kafka.bootstrap.servers' as json_key
       , trim(split_part(unnest(string_to_array(replace((a.context_value::json->'src.kafka.bootstrap.servers')::varchar,'"',''), ',')),':',1)) as json_value
    from zq_kafka_info a
   where 1 = 1
     and a.app_type = 'WORKER'
     and a.context_value like '%"src.kafka.bootstrap.servers"%'
     
     SELECT zki.context_name ,zki.context_value  FROM zq_kafka_info zki    where 1 = 1
     and zki.app_type = 'WORKER'
     and zki.context_value like '%"src.kafka.bootstrap.servers"%' 이걸 oracle로 바꿔줘. oracle-19c

## ChatGPT 응답:
> 주어진 PostgreSQL 쿼리를 Oracle 19c 쿼리로 변환하겠습니다.

첫 번째 쿼리:

```sql
WITH CTE AS (
    SELECT a.cluster_nm, 
           a.app_type, 
           a.srv_ip, 
           a.context_name, 
           'src.kafka.bootstrap.servers' as json_key,
           REGEXP_REPLACE(a.context_value, '"', '') AS cleaned_value,
           LEVEL AS lvl
    FROM zq_kafka_info a
    WHERE a.app_type = 'WORKER'
    AND a.context_value LIKE '%"src.kafka.bootstrap.servers"%'
    CONNECT BY PRIOR a.cluster_nm = a.cluster_nm
        AND PRIOR DBMS_RANDOM.VALUE IS NOT NULL
        AND LEVEL <= LENGTH(REGEXP_REPLACE(a.context_value, '"', '')) - LENGTH(REPLACE(REGEXP_REPLACE(a.context_value, '"', ''), ',', '')) + 1
)
SELECT cluster_nm, app_type, srv_ip, context_name, json_key,
       TRIM(SUBSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), 1, INSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), ':')-1)) as json_value
FROM CTE
WHERE INSTR(cleaned_value, ',', 1, lvl) != 0 OR lvl = 1
```

두 번째 쿼리:

```sql
SELECT zki.context_name, zki.context_value
FROM zq_kafka_info zki
WHERE zki.app_type = 'WORKER'
AND zki.context_value LIKE '%"src.kafka.bootstrap.servers"%'
```

이 쿼리는 PostgreSQL 쿼리와 거의 유사한데, 문자열을 파싱하고 배열을 생성하는 로직이 조금 다릅니다. 첫 번째 쿼리에서는 문자열에서 서버 IP나 도메인 이름만 추출하고, 두 번째 쿼리는 해당 필터에 일치하는 모든 `context_name`과 `context_value`를 반환합니다.

## 사용자 입력:
> 첫번째 query실행했더니, ip가 아닌것도 json_value에 나오네.

## ChatGPT 응답:
> 죄송합니다. 문제가 되는 부분을 해결하기 위해 쿼리를 조정하겠습니다.

다음은 IP 주소 또는 도메인 이름을 추출하기 위해 수정된 첫 번째 쿼리입니다:

```sql
WITH CTE AS (
    SELECT a.cluster_nm, 
           a.app_type, 
           a.srv_ip, 
           a.context_name, 
           'src.kafka.bootstrap.servers' as json_key,
           REGEXP_REPLACE(a.context_value, '"', '') AS cleaned_value,
           LEVEL AS lvl
    FROM zq_kafka_info a
    WHERE a.app_type = 'WORKER'
    AND a.context_value LIKE '%"src.kafka.bootstrap.servers"%'
    CONNECT BY PRIOR a.cluster_nm = a.cluster_nm
        AND PRIOR DBMS_RANDOM.VALUE IS NOT NULL
        AND LEVEL <= LENGTH(REGEXP_REPLACE(a.context_value, '"', '')) - LENGTH(REPLACE(REGEXP_REPLACE(a.context_value, '"', ''), ',', '')) + 1
)
SELECT cluster_nm, app_type, srv_ip, context_name, json_key,
       CASE 
         WHEN REGEXP_LIKE(TRIM(SUBSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), 1, INSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), ':')-1)), '^([0-9]{1,3}\.){3}[0-9]{1,3}$') OR
              REGEXP_LIKE(TRIM(SUBSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), 1, INSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), ':')-1)), '^[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$')
         THEN TRIM(SUBSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), 1, INSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), ':')-1))
       END AS json_value
FROM CTE
WHERE (INSTR(cleaned_value, ',', 1, lvl) != 0 OR lvl = 1)
AND (REGEXP_LIKE(TRIM(SUBSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), 1, INSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), ':')-1)), '^([0-9]{1,3}\.){3}[0-9]{1,3}$') OR
     REGEXP_LIKE(TRIM(SUBSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), 1, INSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), ':')-1)), '^[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'))
```

변경 사항:
1. `CASE`문을 사용하여 IP 주소 패턴 또는 도메인 이름 패턴과 일치하는 값만 `json_value`에 포함되도록 수정하였습니다.
2. IP 주소는 `^([0-9]{1,3}\.){3}[0-9]{1,3}$` 패턴과, 도메인 이름은 `^[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$` 패턴과 일치하는지 확인하였습니다.

위 쿼리를 다시 실행하여 IP 주소 또는 도메인 이름만 추출되는지 확인해 보세요.

## 사용자 입력:
> ip만 나오면 돼.

## ChatGPT 응답:
> 네, IP 주소만 추출하도록 쿼리를 수정하겠습니다. 

IP 주소 패턴 (`^([0-9]{1,3}\.){3}[0-9]{1,3}$`)만을 사용하여 `json_value`에서 IP 주소만 필터링합니다.

```sql
WITH CTE AS (
    SELECT a.cluster_nm, 
           a.app_type, 
           a.srv_ip, 
           a.context_name, 
           'src.kafka.bootstrap.servers' as json_key,
           REGEXP_REPLACE(a.context_value, '"', '') AS cleaned_value,
           LEVEL AS lvl
    FROM zq_kafka_info a
    WHERE a.app_type = 'WORKER'
    AND a.context_value LIKE '%"src.kafka.bootstrap.servers"%'
    CONNECT BY PRIOR a.cluster_nm = a.cluster_nm
        AND PRIOR DBMS_RANDOM.VALUE IS NOT NULL
        AND LEVEL <= LENGTH(REGEXP_REPLACE(a.context_value, '"', '')) - LENGTH(REPLACE(REGEXP_REPLACE(a.context_value, '"', ''), ',', '')) + 1
)
SELECT cluster_nm, app_type, srv_ip, context_name, json_key,
       CASE 
         WHEN REGEXP_LIKE(TRIM(SUBSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), 1, INSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), ':')-1)), '^([0-9]{1,3}\.){3}[0-9]{1,3}$') 
         THEN TRIM(SUBSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), 1, INSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), ':')-1))
       END AS json_value
FROM CTE
WHERE (INSTR(cleaned_value, ',', 1, lvl) != 0 OR lvl = 1)
AND REGEXP_LIKE(TRIM(SUBSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), 1, INSTR(REGEXP_SUBSTR(cleaned_value, '[^,]+', 1, lvl), ':')-1)), '^([0-9]{1,3}\.){3}[0-9]{1,3}$')
```

위의 쿼리는 `json_value`에 IP 주소만을 포함하도록 수정되었습니다. 

쿼리를 실행하여 IP 주소만이 `json_value`에 나타나는지 확인해 보세요.

